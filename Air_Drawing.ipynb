{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Projet - Air Drawing\n",
    "---\n",
    "EXPLICATION DE LA PROBLEMATIQUE"
   ],
   "id": "30bbd429f65f49f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Datsets",
   "id": "db1b647ba468abcc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### EMNIST\n",
    "EXPLICATION"
   ],
   "id": "43e3c57ff07e0f50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### AUTRE DATASET\n",
    "EXPLICATION"
   ],
   "id": "9933c1334e506add"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrainement de lettres",
   "id": "874f068e71321ccb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Option A (CNN Maison)",
   "id": "f2ccc68d2194a28f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### CCN Maison 1",
   "id": "4c469c4ae2b0c248"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Modèle",
   "id": "43c4e66cd8b6a40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "5199db07d7bd5ad1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Tableau d'apprentissage",
   "id": "959b97c77a4f09f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "6b005241b7adeccf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### CCN Maison 2",
   "id": "85e88e7277fdb498"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Modèle",
   "id": "20c3665720a7bcb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "ecb4448a5de0e45f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Tableau d'apprentissage",
   "id": "465da765a2ece86a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "8281780cbce591ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Option B (Transfert Learning)",
   "id": "9fc6b59c4c968ade"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Transfer Learning 1 (XXX)",
   "id": "2abb7ec715bf4edb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Modèle Feature Extraction",
   "id": "5fdfa4a23d219d5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "84b9315a6b7eb381"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Tableau d'apprentissage (Feature Extraction)",
   "id": "2f42ad0ead12c2a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "8a43dae76236c921"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Modèle Fine-tuning",
   "id": "6deabe09200a933d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "32e36caa48b641ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Tableau d'apprentissage (Fine-tuning)",
   "id": "747ee788ea63db6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "dab9dbbdf61ab4d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Transfer Learning 2 (XXX)",
   "id": "f84ad8cfd937bb9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Modèle Feature Extraction",
   "id": "cbe0bdc945bac6af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "6ead5f11a093667a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Tableau d'apprentissage (Feature Extraction)",
   "id": "fbe069ed6bb82e1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "5fa2072b56ce6d60"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Modèle Fine-tuning",
   "id": "7d4dc07d7bbbfaf8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "afd8abf65aa561e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Tableau d'apprentissage (Fine-tuning)",
   "id": "bae40c2c183b3b1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "7d9c89e01d41167f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Évaluation Comparative et Analyse Critique\n",
    "Explication et résumer des résultat avec les tableaux etc\n",
    "Meilleur modele dans quel cas et pourquoi (temps, MSE, accuracy, etc)"
   ],
   "id": "5d7c813d2b5ce0ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Vidéo",
   "id": "c64cf9968ff01548"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === Fonctions utilitaires ===\n",
    "def vider_dossier(dossier):\n",
    "    if os.path.exists(dossier):\n",
    "        for f in os.listdir(dossier):\n",
    "            chemin = os.path.join(dossier, f)\n",
    "            if os.path.isfile(chemin):\n",
    "                os.remove(chemin)\n",
    "    else:\n",
    "        os.makedirs(dossier)\n",
    "\n",
    "# === 0. Définition des chemins ===\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "print(BASE_DIR)\n",
    "video_path = os.path.join(BASE_DIR, 'videos/Lettres/I.mp4')\n",
    "extracted_dir = os.path.join(BASE_DIR, 'images_extraites')\n",
    "finger_dir = os.path.join(BASE_DIR, 'finger_find')\n",
    "frame_interval = 2\n",
    "\n",
    "# === 1. Nettoyage des dossiers ===\n",
    "vider_dossier(extracted_dir)\n",
    "vider_dossier(finger_dir)\n",
    "\n",
    "# === 2. Extraction des frames ===\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Erreur : impossible d'ouvrir la vidéo '{video_path}'\")\n",
    "    exit()\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"Vidéo chargée : {total_frames} frames à {fps:.2f} fps\")\n",
    "\n",
    "frame_count = 0\n",
    "saved_count = 0\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    if frame_count % frame_interval == 0:\n",
    "        filename = os.path.join(extracted_dir, f\"frame_{saved_count:04d}.jpg\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        saved_count += 1\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "print(f\"{saved_count} images extraites dans le dossier '{extracted_dir}'\")\n",
    "\n",
    "# === 3. Détection du bout de l'index ===\n",
    "trace_points = []\n",
    "img_shape = None\n",
    "detector = HandDetector(staticMode=True, maxHands=1, detectionCon=0.7)\n",
    "\n",
    "#for filename in os.listdir(extracted_dir):\n",
    "for filename in sorted(os.listdir(extracted_dir)):\n",
    "    if not filename.endswith(('.jpg', '.png')):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(extracted_dir, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    hands, img = detector.findHands(image)\n",
    "\n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        lm_list = hand['lmList']\n",
    "        if len(lm_list) >= 9:\n",
    "            x, y = lm_list[8][0], lm_list[8][1]\n",
    "            trace_points.append((x, y))\n",
    "\n",
    "    #cv2.imwrite(os.path.join(finger_dir, filename), img)\n",
    "\n",
    "# === 4. Génération de l'image composite ===\n",
    "#sample_img = cv2.imread(os.path.join(finger_dir, os.listdir(finger_dir)[0]))\n",
    "if img_shape is None:\n",
    "    img_shape = image.shape\n",
    "\n",
    "height, width, _ = img_shape\n",
    "result = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "for i in range(1, len(trace_points)):\n",
    "    cv2.line(result, trace_points[i - 1], trace_points[i], (0, 0, 255), thickness=6)\n",
    "\n",
    "#for filename in os.listdir(finger_dir):\n",
    "#    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "#        path = os.path.join(finger_dir, filename)\n",
    "#        img = cv2.imread(path)\n",
    "#        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "#\n",
    "#        lower_red1 = np.array([0, 100, 100])\n",
    "#        upper_red1 = np.array([10, 255, 255])\n",
    "#        lower_red2 = np.array([160, 100, 100])\n",
    "#        upper_red2 = np.array([180, 255, 255])\n",
    "#\n",
    "#        mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "#        mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "#        mask = mask1 | mask2\n",
    "#\n",
    "#        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#        if contours:\n",
    "#            biggest = max(contours, key=cv2.contourArea)\n",
    "#            if cv2.contourArea(biggest) > 0:\n",
    "#                cv2.drawContours(result, [biggest], -1, (0, 0, 255), -1)\n",
    "\n",
    "# === 5. Rotation de 90° vers la droite ===\n",
    "rotated = cv2.rotate(result, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "# === 6. Effet miroir (symétrie horizontale) ===\n",
    "mirrored = cv2.flip(rotated, 1)\n",
    "\n",
    "# === 7. Sauvegarde de l'image finale ===\n",
    "cv2.imwrite(\"../image_resultat.png\", mirrored)\n",
    "print(\"Image finale enregistrée sous 'image_resultat.png' (rotation + effet miroir)\")\n"
   ],
   "id": "90f763730f7905e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Traitements d'image",
   "id": "aae0c493bf1d7865"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_step_logs(image, name, output_dir=\"debug_steps\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if image is None or image.size == 0:\n",
    "        print(f\"[WARNING] Cannot save '{name}': image is empty.\")\n",
    "        return\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{name}.png\"), image)\n",
    "\n",
    "# Step 1: Extract red from image\n",
    "def extract_red_mask(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower_red1 = np.array([0, 70, 50])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([170, 70, 50])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    return cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "# Step 2: Basic cleaning (open/close)\n",
    "def clean_mask(mask):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    return cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Step 3: Keep relevant parts\n",
    "def filter_components(mask, min_area=50):\n",
    "    labeled = label(mask)\n",
    "    cleaned = np.zeros_like(mask)\n",
    "    for region in regionprops(labeled):\n",
    "        if region.area >= min_area:\n",
    "            for y, x in region.coords:\n",
    "                cleaned[y, x] = 255\n",
    "    return cleaned\n",
    "\n",
    "# Step 4: Skeletonize\n",
    "def get_skeleton(mask):\n",
    "    return (skeletonize(mask > 0) * 255).astype(np.uint8)\n",
    "\n",
    "# Step 5 : Bold the ligne\n",
    "def thicken_mask(mask, size=3):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (size, size))\n",
    "    return cv2.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "# Step 6: Resize and center\n",
    "def center_and_resize(mask, output_size=28, margin=2):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return np.ones((output_size, output_size), dtype=np.uint8) * 255\n",
    "    x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "    cropped = mask[y:y+h, x:x+w]\n",
    "    resized = cv2.resize(cropped, (output_size - 2 * margin, output_size - 2 * margin))\n",
    "    canvas = np.ones((output_size, output_size), dtype=np.uint8) * 255\n",
    "    cx = (output_size - resized.shape[1]) // 2\n",
    "    cy = (output_size - resized.shape[0]) // 2\n",
    "    canvas[cy:cy + resized.shape[0], cx:cx + resized.shape[1]] = 255 - resized\n",
    "\n",
    "    return canvas\n",
    "\n",
    "# Main function\n",
    "def process_image(path, output_dir=\"debug_steps\"):\n",
    "    img = cv2.imread(path)\n",
    "    save_step_logs(img, \"00_original\", output_dir)\n",
    "\n",
    "    mask = extract_red_mask(img)\n",
    "    save_step_logs(mask, \"01_red_mask\", output_dir)\n",
    "\n",
    "    cleaned = clean_mask(mask)\n",
    "    save_step_logs(cleaned, \"02_cleaned\", output_dir)\n",
    "\n",
    "    filtered = filter_components(cleaned)\n",
    "    save_step_logs(filtered, \"03_filtered\", output_dir)\n",
    "\n",
    "    skeleton = get_skeleton(filtered)\n",
    "    save_step_logs(skeleton, \"04_skeleton\", output_dir)\n",
    "\n",
    "    thickened = thicken_mask(skeleton, size=50)\n",
    "    save_step_logs(thickened, \"05_thickened\", output_dir)\n",
    "\n",
    "    final = center_and_resize(thickened)\n",
    "    save_step_logs(final, \"06_final\", output_dir)\n",
    "\n",
    "    print(\"[INFO] Simplified processing complete.\")\n",
    "    cv2.imwrite(os.path.join(\"../Resultats/Conversion\", \"result.png\"), final)\n",
    "\n",
    "    return final\n",
    "\n",
    "# Run on your image\n",
    "process_image(\"../image_resultat.png\")"
   ],
   "id": "c64c1ca6347516f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test \"Réel\"",
   "id": "d023b33e7d8a802a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TO DO",
   "id": "91cc16adfc7ff593"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Conclusions et Décisions",
   "id": "a468053764ea2bc3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
